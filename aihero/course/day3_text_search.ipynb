{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3ff1b50-d912-4067-8975-fab8133a092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from minsearch import Index\n",
    "\n",
    "def read_repo_data(repo_owner, repo_name, branch=\"main\"):\n",
    "    \"\"\"\n",
    "      Download and parse all markdown files from a GitHub repository.\n",
    "    Yields one document (dict) at a time to avoid loading everything into memory.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner (str): GitHub username or organization\n",
    "        repo_name (str): Repository name\n",
    "        branch (str): Branch name (default: main)\n",
    "\n",
    "    \"\"\"\n",
    "    url = f\"https://codeload.github.com/{repo_owner}/{repo_name}/zip/refs/heads/{branch}\"\n",
    "    resp = requests.get(url)\n",
    "\n",
    "    if resp.status_code == 404 and branch == \"main\":\n",
    "        # Try fallback to master\n",
    "        return read_repo_data(repo_owner, repo_name, branch=\"master\")\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: HTTP {resp.status_code}\")\n",
    "    with zipfile.ZipFile(io.BytesIO(resp.content)) as zf:\n",
    "        for file_info in zf.infolist():\n",
    "            filename = file_info.filename\n",
    "            if not filename.lower().endswith((\".md\", \".mdx\")):\n",
    "                continue\n",
    "            try:\n",
    "                with zf.open(file_info) as f_in:\n",
    "                    content = f_in.read().decode(\"utf-8\", errors=\"replace\")\n",
    "                    post = frontmatter.loads(content)\n",
    "                    data = post.to_dict()\n",
    "                    data.update({\n",
    "                        \"filename\": filename,\n",
    "                        \"repo\": repo_name,\n",
    "                        \"owner\": repo_owner,\n",
    "                        \"branch\": branch\n",
    "                    })\n",
    "                    yield data\n",
    "            except Exception as e:\n",
    "                logging.warning(\"Error processing %s: %s\", filename, e)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40e451e7-7cbd-48d1-80a6-786dbd2e7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq, size, step):\n",
    "    \"\"\"Yield overlapping chunks from a long string.\"\"\"\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "    n = len(seq)\n",
    "    for i in range(0, n, step):\n",
    "        yield {\"start\": i, \"chunk\": seq[i:i+size]}\n",
    "        if i + size >= n:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bc5e41f-65a7-466d-9cb0-fb7ad4e6be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading and chunking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 95it [00:01, 61.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collected 575 chunks. Building index...\n",
      "‚úÖ Indexing complete!\n",
      "\n",
      "üîé Result 1\n",
      "üìÑ Title: RAG evaluation dataset\n",
      "üìù Description: Synthetic data for RAG.\n",
      "üìÇ File: docs-main/synthetic-data/rag_data.mdx\n",
      "üìñ Content Preview:\n",
      "Retrieval-Augmented Generation (RAG) systems rely on retrieving answers from a knowledge base before generating responses. To evaluate them effectively, you need a test dataset that reflects what the system *should* know.\n",
      "\n",
      "Instead of manually creating test cases, you can generate them directly from your knowledge source, ensuring accurate and relevant ground truth data.\n",
      "\n",
      "## Create a RAG test datas...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üîé Result 2\n",
      "üìÑ Title: LLM Evaluation\n",
      "üìù Description: Evaluate text outputs in under 5 minutes\n",
      "üìÇ File: docs-main/quickstart_llm.mdx\n",
      "üìñ Content Preview:\n",
      " Inputs, context, and outputs (for RAG evaluation)\n",
      "</Info>\n",
      "\n",
      "<Info>\n",
      "  **Collecting live data**. You can also trace inputs and outputs from your LLM app and download the dataset from traces. See the [Tracing Quickstart](/quickstart_tracing)\n",
      "</Info>\n",
      "\n",
      "## 3. Run evaluations\n",
      "\n",
      "We'll evaluate the answers for:\n",
      "\n",
      "- **Sentiment:** from -1 (negative) to 1 (positive)\n",
      "- **Text length:** character count\n",
      "- **Denia...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Downloading and chunking documents...\")\n",
    "all_chunks = []\n",
    "\n",
    "for doc in tqdm(read_repo_data(\"evidentlyai\", \"docs\"), desc=\"Processing files\"):\n",
    "    doc_copy = doc.copy()\n",
    "    content = doc_copy.pop(\"content\", \"\")\n",
    "    for chunk in sliding_window(content, size=2000, step=1000):\n",
    "        chunk.update(doc_copy)\n",
    "        all_chunks.append(chunk)\n",
    "\n",
    "print(f\"Collected {len(all_chunks)} chunks. Building index...\")\n",
    "\n",
    "index = Index(\n",
    "    text_fields=[\"chunk\", \"title\", \"description\", \"filename\"],\n",
    "    keyword_fields=[]\n",
    ")\n",
    "index.fit(all_chunks)\n",
    "\n",
    "print(\" Indexing complete!\")\n",
    "\n",
    "def text_search(query, num_results=2):\n",
    "    results = index.search(query, num_results=num_results)\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"\\nüîé Result {i}\")\n",
    "        print(f\"üìÑ Title: {r.get('title', '(no title)')}\")\n",
    "        print(f\"üìù Description: {r.get('description', '(no description)')}\")\n",
    "        print(f\"üìÇ File: {r['filename']}\")\n",
    "        print(f\"üìñ Content Preview:\\n{r['chunk'][:400]}...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "\n",
    "# Example search\n",
    "query = \"What should be in a test dataset for AI evaluation?\"\n",
    "text_search(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
